# Awesome AI Papers ⭐️

## Description
This repository is an up-to-date list of significant AI papers organized by publication date. It covers five fields : computer vision, natural language processing, audio processing, multimodal learning and reinforcement learning. Feel free to give this repository a star if you enjoy the work.

Original repo, occasionally re-merged: [Aimerou Ndiaye](https://github.com/aimerou/-awesome-ai-papers)
This repo maintained by: [Misrab](https://github.com/misrab)

## Taxonomy
To select the most relevant papers, we chose subjective limits in terms of number of citations. Each icon here designates a paper type that meets one of these criteria.

:trophy: Historical Paper : more than 10k citations and a decisive impact in the evolution of AI.

:star: Important Paper : more than 50 citations and state of the art results.

:arrow_double_up: Trend : 1 to 50 citations, recent and innovative paper with growing adoption.

:newspaper: Important Article : decisive work that was not accompanied by a research paper.

## Table of Contents
- [Historical Papers](#1)
- [Computer Vision](#2)
- [Natural Language Processing](#3)
- [Audio Processing](#4)
- [Multimodal Learning](#5)
- [Reinforcement Learning](#6)
- [Other Papers](#7)
- "-->" want to read soon; "[yyyy-mm-dd]" read date

----

## Misc <a name="0"></a>

Cohere AI 

* [Which Prompts Make The Difference? Data Prioritization For Efficient Human LLM Evaluation](https://cohere.com/research/papers/which-prompts-make-the-difference-data-prioritization-for-efficient-human-llm-evaluation-2023-10-22)
* [Goodtriever: Adaptive Toxicity Mitigation with Retrieval-augmented Models](https://cohere.com/research/papers/goodtriever-adaptive-toxicity-mitigation-with-retrieval-augmented-models-2023-10-11)
* [The Grand Illusion: The Myth of Software Portability and Implications for ML Progress](https://cohere.com/research/papers/the-grand-illusion-the-myth-of-software-portability-and-implications-for-ml-progress-2023-09-12)
* [Pushing Mixture of Experts to the Limit: Extremely Parameter Efficient MoE for Instruction Tuning](https://cohere.com/research/papers/pushing-mixture-of-experts-to-the-limit-extremely-parameter-efficient-moe-for-instruction-tuning-2023-09-11)
* --> [When Less is More: Investigating Data Pruning for Pretraining LLMs at Scale](https://cohere.com/research/papers/when-less-is-more-investigating-data-pruning-for-pretraining-llms-at-scale-2023-09-08)
* --> [Intriguing Properties of Quantization at Scale](https://cohere.com/research/papers/intriguing-properties-of-quantization-at-scale-2023-05-30)
* --> [Efficient Methods for Natural Language Processing: A Survey](https://arxiv.org/abs/2209.00099)

Anthropic

* --> [Towards Monosemanticity: Decomposing Language Models With Dictionary Learning](https://transformer-circuits.pub/2023/monosemantic-features/index.html)
* [In-context Learning and Induction Heads](https://www.anthropic.com/index/in-context-learning-and-induction-heads)
* [A Mathematical Framework for Transformer Circuits](https://www.anthropic.com/index/a-mathematical-framework-for-transformer-circuits)
* [Language Models (Mostly) Know What They Know](https://www.anthropic.com/index/language-models-mostly-know-what-they-know)
* [Softmax Linear Units](https://www.anthropic.com/index/softmax-linear-units)
* [Superposition, Memorization, and Double Descent](https://transformer-circuits.pub/2023/toy-double-descent/index.html)
* [Distributed Representations: Composition & Superposition](https://transformer-circuits.pub/2023/superposition-composition/index.html)
* [Interpretability Dreams](https://transformer-circuits.pub/2023/interpretability-dreams/index.html)
* [Circuits Updates — May 2023](https://transformer-circuits.pub/2023/may-update/index.html#two-circles)
* [Question Decomposition Improves the Faithfulness of Model-Generated Reasoning](https://www-files.anthropic.com/production/files/question-decomposition-improves-the-faithfulness-of-model-generated-reasoning.pdf)
* [Measuring Faithfulness in Chain-of-Thought Reasoning](https://www-files.anthropic.com/production/files/measuring-faithfulness-in-chain-of-thought-reasoning.pdf)
* [Towards understanding Sycophancy](https://arxiv.org/pdf/2310.13548.pdf):w


## Coding, Computation, Maths <a name="8"></a>
* --> :star: 02/2022: [Competition-Level Code Generation with AlphaCode (AlphaCode)](https://www.science.org/doi/full/10.1126/science.abq1158)
* --> :star: 06/2022: [Solving Quantitative Reasoning Problems with Language Models (Minerva)](https://arxiv.org/abs/2206.14858)


## Biotech <a name="9"></a>
* --> :trophy: 2021: [Highly accurate protein structure prediction with AlphaFold (Alphafold)](https://www.nature.com/articles/s41586-021-03819-2)
* --> :star: 05/2022: [ColabFold: making protein folding accessible to all (ColabFold)](https://www.nature.com/articles/s41592-022-01488-1)


## Historical Papers <a name="1"></a>
* :trophy: 1958: [Perceptron: A probabilistic model for information storage and organization in the brain (Perceptron)](https://psycnet.apa.org/record/1959-09865-001)
* :trophy: 1986: [Learning representations by back-propagating errors (Backpropagation)](https://www.nature.com/articles/323533a0)
* :trophy: 1986: [Induction of decision trees (CART)](https://link.springer.com/article/10.1007/BF00116251)
* :trophy: 1989: [A Tutorial on Hidden Markov Models and Selected Applications in Speech Recognition (HMM)](https://ieeexplore.ieee.org/abstract/document/18626)
* --> :trophy: 1989: [Multilayer feedforward networks are universal approximators](https://www.sciencedirect.com/science/article/abs/pii/0893608089900208)
* :trophy: 1992: [A training algorithm for optimal margin classifiers (SVM)](https://dl.acm.org/doi/10.1145/130385.130401)
* :trophy: 1996: [Bagging predictors](https://link.springer.com/article/10.1007/BF00058655)
* :trophy: 1998: [Gradient-based learning applied to document recognition (CNN/GTN)](https://ieeexplore.ieee.org/abstract/document/726791)
* :trophy: 2001: [Random Forests](https://link.springer.com/article/10.1023/a:1010933404324)
* :trophy: 2001: [A fast and elitist multiobjective genetic algorithm (NSGA-II)](https://ieeexplore.ieee.org/abstract/document/996017)
* :trophy: 2003: [Latent Dirichlet Allocation (LDA)](https://jmlr.csail.mit.edu/papers/v3/blei03a.html)
* --> :trophy: 2006: [Reducing the Dimensionality of Data with Neural Networks (Autoencoder)](https://www.science.org/doi/abs/10.1126/science.1127647)
* --> :trophy: 2008: [Visualizing Data using t-SNE (t-SNE)](https://www.jmlr.org/papers/v9/vandermaaten08a.html)
* :trophy: 2009: [ImageNet: A large-scale hierarchical image database (ImageNet)](https://ieeexplore.ieee.org/document/5206848)
* :trophy: 2012: [ImageNet Classification with Deep Convolutional Neural Networks (AlexNet)](https://papers.nips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html)
* --> :trophy: 2013: [Efficient Estimation of Word Representations in Vector Space (Word2vec)](https://arxiv.org/abs/1301.3781)
* --> :trophy: 2013: [Auto-Encoding Variational Bayes (VAE)](https://arxiv.org/abs/1312.6114)
* --> :trophy: 2014: [Generative Adversarial Networks (GAN)](https://papers.nips.cc/paper/2014/hash/5ca3e9b122f61f8f06494c97b1afccf3-Abstract.html)
* [2023-10] :trophy: 2014: [Dropout: A Simple Way to Prevent Neural Networks from Overfitting (Dropout)](https://jmlr.org/papers/v15/srivastava14a.html)
* :trophy: 2014: [Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation](https://arxiv.org/abs/1406.1078)
* :trophy: 2014: [Adam: A Method for Stochastic Optimization (Adam)](https://arxiv.org/abs/1412.6980)
* [2023-10] :trophy: 2015: [Batch Normalization: Accelerating Deep Network Training by Reducing Internal Cov... (BatchNorm)](http://proceedings.mlr.press/v37/ioffe15.html)
* --> :trophy: 2015: [Going Deeper With Convolutions (Inception)](https://www.cv-foundation.org/openaccess/content_cvpr_2015/html/Szegedy_Going_Deeper_With_2015_CVPR_paper.html)
* --> :trophy: 2015: [Human-level control through deep reinforcement learning (Deep Q Network)](https://www.nature.com/articles/nature14236/)
* :trophy: 2015: [Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks (Faster R-CNN)](https://papers.nips.cc/paper/2015/hash/14bfa6bb14875e45bba028a21ed38046-Abstract.html)
* :trophy: 2015: [U-Net: Convolutional Networks for Biomedical Image Segmentation (U-Net)](https://arxiv.org/abs/1505.04597)
* :trophy: 2015: [Deep Residual Learning for Image Recognition (ResNet)](https://arxiv.org/abs/1512.03385)
* :trophy: 2016: [You Only Look Once: Unified, Real-Time Object Detection (YOLO)](https://www.cv-foundation.org/openaccess/content_cvpr_2016/html/Redmon_You_Only_Look_CVPR_2016_paper.html)
* [2023-10] :trophy: 2017: [Attention is All you Need (Transformer)](https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html)
* --> :trophy: 2018: [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding (BERT)](https://arxiv.org/abs/1810.04805)
* --> :trophy: 2020: [Language Models are Few-Shot Learners (GPT-3)](https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html)
* :newspaper: 2022: [ChatGPT: Optimizing Language Models For Dialogue (ChatGPT)](https://openai.com/blog/chatgpt/)

## Computer Vision <a name="2"></a>
* --> :star: 01/2022: [A ConvNet for the 2020s (ConvNeXt)](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_A_ConvNet_for_the_2020s_CVPR_2022_paper.html)
* :star: 01/2022: [Patches Are All You Need (ConvMixer)](https://arxiv.org/abs/2201.09792)
* :star: 02/2022: [Block-NeRF: Scalable Large Scene Neural View Synthesis (Block-NeRF)](https://openaccess.thecvf.com/content/CVPR2022/html/Tancik_Block-NeRF_Scalable_Large_Scene_Neural_View_Synthesis_CVPR_2022_paper.html)
* :star: 03/2022: [DINO: DETR with Improved DeNoising Anchor Boxes for End-to-End Object Detection (DINO)](https://openreview.net/forum?id=3mRwyG5one)
* :star: 03/2022: [Scaling Up Your Kernels to 31×31: Revisiting Large Kernel Design in CNNs (Large Kernel CNN)](https://openaccess.thecvf.com/content/CVPR2022/html/Ding_Scaling_Up_Your_Kernels_to_31x31_Revisiting_Large_Kernel_Design_CVPR_2022_paper.html)
* :star: 03/2022: [TensoRF: Tensorial Radiance Fields (TensoRF)](https://link.springer.com/chapter/10.1007/978-3-031-19824-3_20)
* :star: 04/2022: [MaxViT: Multi-Axis Vision Transformer (MaxViT)](https://arxiv.org/abs/2204.01697)
* :star: 04/2022: [Hierarchical Text-Conditional Image Generation with CLIP Latents (DALL-E 2)](https://arxiv.org/abs/2204.06125)
* :star: 05/2022: [Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding (Imagen)](https://arxiv.org/abs/2205.11487)
* :star: 05/2022: [GIT: A Generative Image-to-text Transformer for Vision and Language (GIT)](https://arxiv.org/abs/2205.14100)
* :star: 06/2022: [CMT: Convolutional Neural Network Meet Vision Transformers (CMT)](https://openaccess.thecvf.com/content/CVPR2022/html/Guo_CMT_Convolutional_Neural_Networks_Meet_Vision_Transformers_CVPR_2022_paper.html)
* :star: 07/2022: [Swin UNETR: Swin Transformers for Semantic Segmentation of Brain Tumors... (Swin UNETR)](https://link.springer.com/chapter/10.1007/978-3-031-08999-2_22)
* :star: 07/2022: [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598)
* :star: 08/2022: [Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation (DreamBooth)](https://arxiv.org/abs/2208.12242)
* :star: 09/2022: [DreamFusion: Text-to-3D using 2D Diffusion (DreamFusion)](https://arxiv.org/abs/2209.14988)
* :star: 09/2022: [Make-A-Video: Text-to-Video Generation without Text-Video Data (Make-A-Video)](https://arxiv.org/abs/2209.14792)
* :star: 10/2022: [On Distillation of Guided Diffusion Models](https://arxiv.org/abs/2210.03142)
* :star: 10/2022: [LAION-5B: An open large-scale dataset for training next generation image-text models (LAION-5B)](https://arxiv.org/abs/2210.08402)
* :star: 10/2022: [Imagic: Text-Based Real Image Editing with Diffusion Models (Imagic)](https://arxiv.org/abs/2210.09276)
* :star: 11/2022: [Visual Prompt Tuning](https://link.springer.com/chapter/10.1007/978-3-031-19827-4_41)
* :star: 11/2022: [DiffusionDet: Diffusion Model for Object Detection (DiffusionDet)](https://arxiv.org/abs/2211.09788)
* :star: 11/2022: [InstructPix2Pix: Learning to Follow Image Editing Instructions (InstructPix2Pix)](https://arxiv.org/abs/2211.09800)
* :star: 12/2022: [Multi-Concept Customization of Text-to-Image Diffusion (Custom Diffusion)](https://arxiv.org/abs/2212.04488)
* :star: 12/2022: [Scalable Diffusion Models with Transformers (DiT)](https://arxiv.org/abs/2212.09748)
* :star: 01/2023: [Muse: Text-To-Image Generation via Masked Generative Transformers (Muse)](https://arxiv.org/abs/2301.00704)
* :star: 02/2023: [Structure and Content-Guided Video Synthesis with Diffusion Models (Gen-1)](https://arxiv.org/abs/2302.03011)
* :star: 02/2023: [Scaling Vision Transformers to 22 Billion Parameters (ViT 22B)](https://arxiv.org/abs/2302.05442)
* :star: 02/2023: [Adding Conditional Control to Text-to-Image Diffusion Models (ControlNet)](https://arxiv.org/abs/2302.05543)
* :star: 03/2023: [Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation Models (Visual ChatGPT)](https://arxiv.org/abs/2303.04671)
* :star: 03/2023: [Scaling up GANs for Text-to-Image Synthesis (GigaGAN)](https://arxiv.org/abs/2303.05511)
* :star: 04/2023: [Segment Anything (SAM)](https://arxiv.org/abs/2304.02643)
* :star: 04/2023: [DINOv2: Learning Robust Visual Features without Supervision (DINOv2)](https://arxiv.org/abs/2304.07193)
* :star: 04/2023: [Align your Latents: High-Resolution Video Synthesis with Latent Diffusion Models (VideoLDM)](https://arxiv.org/abs/2304.08818)
* :star: 04/2023: [Synthetic Data from Diffusion Models Improves ImageNet Classification](https://arxiv.org/abs/2304.08466)
* :star: 04/2023: [Segment Anything in Medical Images (MedSAM)](https://arxiv.org/abs/2304.12306)
* :arrow_double_up: 05/2023: [Drag Your GAN: Interactive Point-based Manipulation on the Generative Image Manifold (DragGAN)](https://arxiv.org/abs/2305.10973)
* :arrow_double_up: 07/2023: [SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis (SDXL)](https://arxiv.org/abs/2307.01952)
* :arrow_double_up: 08/2023: [3D Gaussian Splatting for Real-Time Radiance Field Rendering](https://dl.acm.org/doi/abs/10.1145/3592433)

## NLP <a name="3"></a>
* :star: 01/2022: [LaMBDA: Language Models for Dialog Applications (LaMBDA)](https://arxiv.org/abs/2201.08239)
* :star: 01/2022: [Chain-of-Thought Prompting Elicits Reasoning in Large Language Models (CoT)](https://arxiv.org/abs/2201.11903)
* --> :star: 02/2022: [Finetuned Language Models Are Zero-Shot Learners (FLAN)](https://arxiv.org/abs/2109.01652)
* --> :star: 03/2022: [Training language models to follow human instructions with human feedback (InstructGPT)](https://arxiv.org/abs/2203.02155)
* :star: 03/2022: [Multitask Prompted Training Enables Zero-Shot Task Generalization (T0)](https://arxiv.org/abs/2110.08207)
* :star: 03/2022: [Training Compute-Optimal Large Language Models (Chinchilla)](https://arxiv.org/abs/2203.15556)
* :star: 04/2022: [Do As I Can, Not As I Say: Grounding Language in Robotic Affordances (SayCan)](https://arxiv.org/abs/2204.01691)
* :star: 04/2022: [GPT-NeoX-20B: An Open-Source Autoregressive Language Model (GPT-NeoX)](https://arxiv.org/abs/2204.06745)
* --> :star: 04/2022: [PaLM: Scaling Language Modeling with Pathways (PaLM)](https://arxiv.org/abs/2204.02311)
* :star: 06/2022: [Beyond the Imitation Game: Quantifying and extrapolating the capabilities of lang... (BIG-bench)](https://arxiv.org/abs/2206.04615)
* :star: 10/2022: [ReAct: Synergizing Reasoning and Acting in Language Models (ReAct)](https://arxiv.org/abs/2210.03629)
* :star: 11/2022: [BLOOM: A 176B-Parameter Open-Access Multilingual Language Model (BLOOM)](https://arxiv.org/abs/2211.05100)
* :newspaper: 11/2022: [Optimizing Language Models for Dialogue (ChatGPT)](https://openai.com/blog/chatgpt/)
* :star: 12/2022: [Large Language Models Encode Clinical Knowledge (Med-PaLM)](https://arxiv.org/abs/2212.13138)
* :star: 01/2023: [DetectGPT: Zero-Shot Machine-Generated Text Detection using Probability Curvature (DetectGPT)](https://arxiv.org/abs/2301.11305)
* :star: 02/2023: [Toolformer: Language Models Can Teach Themselves to Use Tools (Toolformer)](https://arxiv.org/abs/2302.04761)
* :star: 02/2023: [LLaMA: Open and Efficient Foundation Language Models (LLaMA)](https://arxiv.org/abs/2302.13971)
* :newspaper: 03/2023: [GPT-4](https://openai.com/research/gpt-4)
* --> :star: 03/2023: [Sparks of Artificial General Intelligence: Early experiments with GPT-4 (GPT-4 Eval)](https://arxiv.org/abs/2303.12712)
* --> :star: 03/2023: [HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFace (HuggingGPT)](https://arxiv.org/abs/2303.17580)
* --> :star: 03/2023: [BloombergGPT: A Large Language Model for Finance (BloombergGPT)](https://arxiv.org/abs/2303.17564)
* :star: 04/2023: [Instruction Tuning with GPT-4](https://arxiv.org/abs/2304.03277)
* --> :star: 04/2023: [Generative Agents: Interactive Simulacra of Human  (Gen Agents)](https://arxiv.org/abs/2304.03442)
* :star: 05/2023: [PaLM 2 Technical Report (PaLM-2)](https://arxiv.org/abs/2305.10403)
* :star: 05/2023: [LIMA: Less Is More for Alignment (LIMA)](https://arxiv.org/abs/2305.11206)
* :star: 05/2023: [QLoRA: Efficient Finetuning of Quantized LLMs (QLoRA)](https://arxiv.org/abs/2305.14314)
* :star: 05/2023: [Voyager: An Open-Ended Embodied Agent with Large Language Models (Voyager)](https://arxiv.org/abs/2305.16291)
* --> :arrow_double_up: 07/2023: [ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs (ToolLLM)](https://arxiv.org/abs/2307.16789)
* --> :arrow_double_up: 08/2023: [MetaGPT: Meta Programming for Multi-Agent Collaborative Framework (MetaGPT)](https://arxiv.org/abs/2308.00352)
* --> :arrow_double_up: 08/2023: [Code Llama: Open Foundation Models for Code (Code Llama)](https://arxiv.org/abs/2308.12950)
* --> :arrow_double_up: 09/2023: [RLAIF: Scaling Reinforcement Learning from Human Feedback with AI Feedback (RLAIF)](https://arxiv.org/abs/2309.00267)
* --> :arrow_double_up: 09/2023: [Large Language Models as Optimizers (OPRO)](https://arxiv.org/abs/2309.03409)

## Audio Processing <a name="4"></a>
* :star: 02/2022: [mSLAM: Massively multilingual joint pre-training for speech and text (mSLAM)](https://arxiv.org/abs/2202.01374)
* :star: 02/2022: [ADD 2022: the First Audio Deep Synthesis Detection Challenge (ADD)](https://arxiv.org/abs/2202.08433)
* :star: 03/2022: [Efficient Training of Audio Transformers with Patchout (PaSST)](https://arxiv.org/abs/2110.05069)
* :star: 04/2022: [MAESTRO: Matched Speech Text Representations through Modality Matching (Maestro)](https://arxiv.org/abs/2204.03409)
* :star: 05/2022: [SpeechT5: Unified-Modal Encoder-Decoder Pre-Training for Spoken Language... (SpeechT5)](https://arxiv.org/abs/2110.07205)
* :star: 06/2022: [WavLM: Large-Scale Self-Supervised Pre-Training for Full Stack Speech Processing (WavLM)](https://ieeexplore.ieee.org/abstract/document/9814838)
* :star: 07/2022: [BigSSL: Exploring the Frontier of Large-Scale Semi-Supervised Learning for ASR (BigSSL)](https://arxiv.org/abs/2109.13226)
* :star: 09/2022: [AudioLM: a Language Modeling Approach to Audio Generation (AudioLM)](https://arxiv.org/abs/2209.03143)
* :star: 09/2022: [AudioGen: Textually Guided Audio Generation (AudioGen)](https://arxiv.org/abs/2209.15352)
* :star: 10/2022: [High Fidelity Neural Audio Compression (EnCodec)](https://arxiv.org/abs/2210.13438)
* :star: 12/2022: [Robust Speech Recognition via Large-Scale Weak Supervision (Whisper)](https://arxiv.org/abs/2212.04356)
* :star: 01/2023: [Neural Codec Language Models are Zero-Shot Text to Speech Synthesizers (VALL-E)](https://arxiv.org/abs/2301.02111)
* :star: 01/2023: [MusicLM: Generating Music From Text (MusicLM)](https://arxiv.org/abs/2301.11325)
* :star: 01/2023: [AudioLDM: Text-to-Audio Generation with Latent Diffusion Models (AudioLDM)](https://arxiv.org/abs/2301.12503)
* :star: 03/2023: [Google USM: Scaling Automatic Speech Recognition Beyond 100 Languages (USM)](https://arxiv.org/abs/2303.01037)
* :arrow_double_up: 03/2023: [Speak Foreign Languages with Your Own Voice: Cross-Lingual Neural Codec... (VALL-E X)](https://arxiv.org/abs/2303.03926)
* :arrow_double_up: 05/2023: [Scaling Speech Technology to 1,000+ Languages (MMS)](https://arxiv.org/abs/2305.13516)
* :arrow_double_up: 06/2023: [Simple and Controllable Music Generation (MusicGen)](https://arxiv.org/abs/2306.05284)
* :arrow_double_up: 06/2023: [AudioPaLM: A Large Language Model That Can Speak and Listen (AudioPaLM)](https://arxiv.org/abs/2306.12925)
* :arrow_double_up: 06/2023: [Voicebox: Text-Guided Multilingual Universal Speech Generation at Scale (Voicebox)](https://arxiv.org/abs/2306.15687)
* :arrow_double_up: 08/2023: [SpeechX: Neural Codec Language Model as a Versatile Speech Transformer (SpeechX)](https://arxiv.org/abs/2308.06873)

## Multimodal Learning <a name="5"></a>
* :star: 01/2022: [BLIP: Boostrapping Language-Image Pre-training for Unified Vision-Language... (BLIP)](https://proceedings.mlr.press/v162/li22n.html)
* :star: 02/2022: [data2vec: A General Framework for Self-supervised Learning in Speech, Vision and... (Data2vec)](https://proceedings.mlr.press/v162/baevski22a.html)
* :star: 03/2022: [VL-Adapter: Parameter-Efficient Transfer Learning for Vision-and-Language Tasks (VL-Adapter)](https://arxiv.org/abs/2112.06825)
* :star: 04/2022: [Winoground: Probing Vision and Language Models for Visio-Linguistic... (Winoground)](https://arxiv.org/abs/2204.03162)
* :star: 04/2022: [Flamingo: a Visual Language Model for Few-Shot Learning (Flamingo)](https://arxiv.org/abs/2204.14198)
* :star: 05/2022: [A Generalist Agent (Gato)](https://arxiv.org/abs/2205.06175)
* :star: 05/2022: [CoCa: Contrastive Captioners are Image-Text Foundation Models (CoCa)](https://arxiv.org/abs/2205.01917)
* :star: 05/2022: [VLMo: Unified Vision-Language Pre-Training with Mixture-of-Modality-Experts (VLMo)](https://arxiv.org/abs/2111.02358)
* :star: 08/2022: [Image as a Foreign Language: BEiT Pretraining for All Vision and Vision-Language Tasks (BEiT)](https://arxiv.org/abs/2208.10442v2)
* :star: 09/2022: [PaLI: A Jointly-Scaled Multilingual Language-Image Model (PaLI)](https://arxiv.org/abs/2209.06794)
* --> :star: 02/2023: [Language Is Not All You Need: Aligning Perception with Language Models (Kosmos-1)](https://arxiv.org/abs/2302.14045v2)
* :star: 03/2023: [PaLM-E: An Embodied Multimodal Language Model (PaLM-E)](https://arxiv.org/abs/2303.03378)
* --> :arrow_double_up: 04/2023: [AudioGPT: Understanding and Generating Speech, Music, Sound, and Talking Head (AudioGPT)](https://arxiv.org/abs/2304.12995)
* :arrow_double_up: 05/2023: [ImageBind: One Embedding Space To Bind Them All (ImageBind)](https://openaccess.thecvf.com/content/CVPR2023/html/Girdhar_ImageBind_One_Embedding_Space_To_Bind_Them_All_CVPR_2023_paper.html)
* :arrow_double_up: 07/2023: [Scaling Autoregressive Multi-Modal Models: Pretraining and Instruction Tuning (CM3Leon)](https://ai.meta.com/research/publications/scaling-autoregressive-multi-modal-models-pretraining-and-instruction-tuning/)
* :arrow_double_up: 07/2023: [Meta-Transformer: A Unified Framework for Multimodal Learning (Meta-Transformer)](https://arxiv.org/abs/2307.10802)
* :arrow_double_up: 08/2023: [Massively Multilingual & Multimodal Machine Translation (SeamlessM4T)](https://arxiv.org/abs/2308.11596v2)

## Reinforcement Learning <a name="6"></a>
* :star: 01/2022: [Learning robust perceptive locomotion for quadrupedal robots in the wild](https://www.science.org/doi/abs/10.1126/scirobotics.abk2822)
* :star: 02/2022: [BC-Z: Zero-Shot Task Generalization with Robotic Imitation Learning](https://proceedings.mlr.press/v164/jang22a.html)
* :star: 02/2022: [Outracing champion Gran Turismo drivers with deep reinforcement learning (Sophy)](https://www.nature.com/articles/s41586-021-04357-7)
* :star: 02/2022: [Magnetic control of tokamak plasmas through deep reinforcement learning](https://www.nature.com/articles/s41586-021-04301-9%E2%80%A6)
* :star: 08/2022: [Learning to Walk in Minutes Using Massively Parallel Deep Reinforcement Learning (ANYmal)](https://arxiv.org/abs/2109.11978)
* :star: 10/2022: [Discovering faster matrix multiplication algorithms with reinforcement learning (AlphaTensor)](https://www.nature.com/articles/s41586-022%20-05172-4)
* :star: 01/2023: [Mastering Diverse Domains through World Models (DreamerV3)](https://arxiv.org/abs/2301.04104)
* :arrow_double_up: 02/2023: [Grounding Large Language Models in Interactive Environments with Online RL (GLAM)](https://arxiv.org/abs/2302.02662)
* :arrow_double_up: 02/2023: [Efficient Online Reinforcement Learning with Offline Data (RLPD)](https://arxiv.org/abs/2302.02948)
* :arrow_double_up: 03/2023: [Reward Design with Language Models](https://arxiv.org/abs/2303.00001)
* :arrow_double_up: 06/2023: [Faster sorting algorithms discovered using deep reinforcement learning (AlphaDev)](https://www.nature.com/articles/s41586-023-06004-9)
* :arrow_double_up: 08/2023: [Retroformer: Retrospective Large Language Agents with Policy Gradient Optimization (Retroformer)](https://arxiv.org/abs/2308.02151)

## Other Papers <a name="7"></a>
* --> :star: 06/2022: [Measuring and Improving the Use of Graph Information in GNN](https://arxiv.org/abs/2206.13170)
* :star: 12/2022: [RT-1: Robotics Transformer for Real-World Control at Scale (RT-1)](https://arxiv.org/abs/2212.06817)
